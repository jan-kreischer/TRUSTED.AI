{
  "parameters": {
    "score_clique_method": {
      "thresholds": {
        "value": [
          0.01,
          0.1,
          0.25,
          0.5
        ],
        "description": "Thresholds of how to map the result of the clique method from 1-5.",
        "label": "Score Thresholds"
      }
    },
    "score_loss_sensitivity": {
      "thresholds": {
        "value": [
          2,
          1.5,
          1,
          0.5
        ],
        "description": "Thresholds of how to map loss sensitivity from 1-5. Smaller value means higher robustness.",
        "label": "Score Thresholds"
      }
    },
    "score_clever_score": {
      "thresholds": {
        "value": [
          0.2,
          0.5,
          1,
          2.5
        ],
        "description": "Thresholds of how to map CLEVER score from 1-5.",
        "label": "Score Thresholds"
      }
    },
    "score_confidence_score": {
      "thresholds": {
        "value": [
          20,
          40,
          60,
          80
        ],
        "description": "Thresholds of how to map confidence score from 1-5. Better confidence score means higher robustness.",
        "label": "Score Thresholds"
      }
    },
    "score_fast_gradient_attack": {
      "thresholds": {
        "value": [
          80,
          60,
          40,
          20
        ],
        "description": "Thresholds of how to map difference between before-after attack accuracies from 1-5. Example: If the before attack accuracy is 85% and after attack accuracy is again 85% it means model is so robust that attack was not successful at all. The difference is 0 and hence this would result in a score of 5 (best score). However if the before attack accuracy was 100% and after attack accuracy is 0% then the model is not robust. The difference is 100% and it would result in score 0 (worst score)",
        "label": "Score Thresholds"
      }
    },
    "score_carlini_wagner_attack": {
      "thresholds": {
        "value": [
          80,
          60,
          40,
          20
        ],
        "description": "Thresholds of how to map difference between before-after attack accuracies from 1-5. Example: If the before attack accuracy is 85% and after attack accuracy is again 85% it means model is so robust that attack was not successful at all. The difference is 0 and hence this would result in a score of 5 (best score). However if the before attack accuracy was 100% and after attack accuracy is 0% then the model is not robust. The difference is 100% and it would result in score 0 (worst score)",
        "label": "Score Thresholds"
      }
    },
    "score_deepfool_attack": {
      "thresholds": {
        "value": [
          80,
          60,
          40,
          20
        ],
        "description": "Thresholds of how to map difference between before-after attack accuracies from 1-5. Example: If the before attack accuracy is 85% and after attack accuracy is again 85% it means model is so robust that attack was not successful at all. The difference is 0 and hence this would result in a score of 5 (best score). However if the before attack accuracy was 100% and after attack accuracy is 0% then the model is not robust. The difference is 100% and it would result in score 0 (worst score)",
        "label": "Score Thresholds"
      }
    }
  },
  "weights": {
    "confidence_score": 0.20,
    "clique_method"    : 0.20,
    "loss_sensitivity"  : 0.20, 
    "clever_score"   : 0.20,
    "er_fast_gradient_attack": 0.20,
    "er_carlini_wagner_attack": 0.20,
    "er_deepfool_attack": 0.20
  },
    "metrics": {
    "confidence_score": "This metric computes how confident the model is about its predictions.<br> The more confident a model is about its prediction the more difficult it is to generate adverserial examples. <br>Hence if the confidence score increases the robustness increases.",
    "clique_method"    : "The clique method calculates a bound estimation for<br> the minimal adversarial perturbation needed to fool the model.",
    "loss_sensitivity"  :"This metric estimates the smoothness of the model.<br>If a small input pertubations create a huge change in output then the model is not considered robust.",
    "clever_score"   : "The clever score can be applied to neural network models. It uses cross lipschitz constant estimation to assess the robustness.",
    "er_fast_gradient_attack": "This metric empirically tests the robustness of models.<br>It tests the model by using Fast Gradient Attack and checks whether the model can be fooled by it.",
    "er_carlini_wagner_attack": "This metric empirically tests the robustness of models.<br>It calculates and applies Carlini Wagner Attack to the model and checks whether the model can be fooled by it.",
    "er_deepfool_attack": "This metric empirically tests the robustness of models.<br>It calculates and applies Deepfool Attack to the model and checks whether the model can be fooled by it."
  }
}